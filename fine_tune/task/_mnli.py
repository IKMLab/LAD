r"""MNLI dataset.

Usage:
    import torch.utils.data.Dataloader
    import fine_tune

    dataset = fine_tune.task.MNLI('train')
    dataset = fine_tune.task.MNLI('dev_matched')
    dataset = fine_tune.task.MNLI('dev_mismatched')
    dataset = fine_tune.task.MNLI(...)

    dataset.update_logits(...)
    dataset.save_for_distill()

    assert fine_tune.task.get_num_label(fine_tune.task.MNLI) == 3

    assert fine_tune.task.label_encoder(
        fine_tune.task.MNLI,
        fine_tune.task.MNLI.allow_labels[0]
    ) == 0

    assert fine_tune.task.label_decoder(
        fine_tune.task.MNLI,
        0
    ) == fine_tune.task.MNLI.allow_labels[0]

    data_loader = torch.utils.data.Dataloader(
        dataset,
        collate_fn=MNLI.create_collate_fn(...)
    )
"""

# built-in modules

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import json
import logging
import os

from typing import List

# 3rd party modules

from tqdm import tqdm

# my own modules

import fine_tune.path

from fine_tune.task._dataset import (
    Dataset,
    Label,
    Sample,
    label_encoder
)

# Get logger.

logger = logging.getLogger('fine_tune.task')

# Define MNLI dataset.


class MNLI(Dataset):
    r"""MultiNLI dataset and its utilities.

    Args:
        dataset:
            Name of MNLI dataset file to be loaded. When `dataset` is the name
            of some previous experiment, it must be MNLI logits dataset
            generated by the model of that experiment.

    Attributes:
        allow_dataset:
            Allowed MNLI dataset. See MNLI paper for more details.
        allow_labels:
            Allowed MNLI labels. We do not consider '-' label. See MNLI paper
            for labeling details.
        dataset:
            A list of MNLI samples.
        task_path:
            Path of MNLI dataset.
    """
    allow_dataset: List[str] = [
        'train',
        'dev_matched',
        'dev_mismatched',
        'test_matched',
        'test_mismatched'
    ]

    allow_labels: List[Label] = [
        'entailment',
        'neutral',
        'contradiction',
    ]

    task_path: str = os.path.join(
        fine_tune.path.FINE_TUNE_DATA,
        'MNLI'
    )

    @staticmethod
    def load(dataset: str) -> List[Sample]:
        r"""Load MNLI dataset into memory.

        This is a heavy IO method and might required lots of memory since
        dataset might be huge. MNLI dataset must be download previously. See
        MNLI document in 'project_root/doc/fine_tune_mnli.md' for downloading
        details.

        Args:
            dataset:
                Name of the MNLI dataset to be loaded.

        Raises:
            FileNotFoundError:
                When MNLI files does not exist.

        Returns:
            A list of MNLI samples.
        """
        try:
            dataset_path = os.path.join(
                MNLI.task_path,
                f'{dataset}.tsv'
            )
            samples = []
            if 'train' in dataset:
                skipped_sample_count = 0
                with open(dataset_path, 'r') as tsv_file:
                    # Skip first line.
                    tsv_file.readline()
                    for sample in tqdm(tsv_file, desc=f'Loading MNLI {dataset}'):
                        # Remove trailing whitespace.
                        sample = sample.strip()
                        index, _, _, _, _, _, _, _, sentence1, sentence2, _, gold_label = sample.split('\t')

                        # Skip sample which label is '-'.
                        # See MNLI paper for labeling details.
                        if gold_label == '-':
                            skipped_sample_count += 1
                            continue
                        samples.append(
                            Sample({
                                'index': int(index),
                                'text': sentence1,
                                'text_pair': sentence2,
                                'label': label_encoder(MNLI, gold_label)
                            })
                        )

                    logger.info(
                        'Number of origin samples: %d',
                        len(samples) + skipped_sample_count
                    )
                    logger.info('Number of skiped samples: %d', skipped_sample_count)
                    logger.info('Number of result samples: %d', len(samples))

                return samples
            elif 'dev' in dataset:
                skipped_sample_count = 0
                with open(dataset_path, 'r') as tsv_file:
                    # Skip first line.
                    tsv_file.readline()
                    for sample in tqdm(tsv_file, desc=f'Loading MNLI {dataset}'):
                        # Remove trailing whitespace.
                        sample = sample.strip()
                        index, _, _, _, _, _, _, _, sentence1, sentence2, _, _, _, _, _, gold_label = sample.split('\t')

                        # Skip sample which label is '-'.
                        # See MNLI paper for labeling details.
                        if gold_label == '-':
                            skipped_sample_count += 1
                            continue
                        samples.append(
                            Sample({
                                'index': int(index),
                                'text': sentence1,
                                'text_pair': sentence2,
                                'label': label_encoder(MNLI, gold_label)
                            })
                        )

                    logger.info(
                        'Number of origin samples: %d',
                        len(samples) + skipped_sample_count
                    )
                    logger.info('Number of skiped samples: %d', skipped_sample_count)
                    logger.info('Number of result samples: %d', len(samples))

                return samples
            else:
                # Loading testing dataset.
                skipped_sample_count = 0
                with open(dataset_path, 'r') as tsv_file:
                    # Skip first line.
                    tsv_file.readline()
                    for sample in tqdm(tsv_file, desc=f'Loading MNLI {dataset}'):
                        # Remove trailing whitespace.
                        sample = sample.strip()
                        index, _, _, _, _, _, _, _, sentence1, sentence2 = sample.split('\t')
                        samples.append(
                            Sample({
                                'index': int(index),
                                'text': sentence1,
                                'text_pair': sentence2,
                                'label': -1
                            })
                        )

                    logger.info(
                        'Number of origin samples: %d',
                        len(samples) + skipped_sample_count
                    )
                    logger.info('Number of skiped samples: %d', skipped_sample_count)
                    logger.info('Number of result samples: %d', len(samples))

                return samples
        except FileNotFoundError as error:
            raise FileNotFoundError(
                f'RTE dataset file {dataset} does not exist.\n' +
                'You must downloaded previously and put it in the path:\n' +
                f'{dataset_path}\n' +
                "See '" +
                os.path.join(fine_tune.path.DOC, 'fine_tune_mnli.md') +
                "' for downloading details."
            ) from error
